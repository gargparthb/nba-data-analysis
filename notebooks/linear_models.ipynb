{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Spliting of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(957, 16) (957,) (169, 16) (169,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/teams_normalized.csv')\n",
    "\n",
    "# separating the dataset into section ready for model fitting\n",
    "train, test = train_test_split(data, test_size=0.15, train_size=0.85)\n",
    "x_cols = ['Age', 'ORtg', 'DRtg', 'NRtg', 'Pace', '3PAr_Norm', 'FTr', 'TS%', 'eFG%', 'TOV%', 'ORB%', 'FT/FGA', 'OeFG%', 'OTOV%', 'DRB%', 'OFT/FGA']\n",
    "y_col = 'W'\n",
    "\n",
    "x_train = train[x_cols]\n",
    "y_train = train[y_col]\n",
    "x_test= test[x_cols]\n",
    "y_test = test[y_col]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some utilities for each of the models we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, model):\n",
    "  pipeline = Pipeline(\n",
    "     steps=[('scaler', StandardScaler()), (model_name, model)]\n",
    "  )\n",
    "  pipeline.fit(x_train, y_train)\n",
    "  print(\"model trained and created\")\n",
    "  return pipeline\n",
    "\n",
    "def score_model(model):\n",
    "  y_pred = model.predict(x_test)\n",
    "  print(\"R2 score =\", round(metrics.r2_score(y_test, y_pred), 2))\n",
    "  print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_pred), 2)) \n",
    "  print(\"Root mean squared error =\", round(math.sqrt(metrics.mean_squared_error(y_test, y_pred)), 2))\n",
    "\n",
    "def unpack_model(model_name, model):\n",
    "  estimator = model.named_steps[model_name]\n",
    "  pprint.pprint(dict(zip(x_cols, estimator.coef_)))\n",
    "  print(\"Intercept: \", estimator.intercept_) \n",
    "\n",
    "def save_model(model, filename):\n",
    "  with open(\"../models/linear_models/\" + filename + \".pickle\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "  print('Model saved as ' + filename + '.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "We can now run the linear regression algorithm on the split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained and created\n"
     ]
    }
   ],
   "source": [
    "linear_regression = create_model('lr', linear_model.LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score = 0.88\n",
      "Mean absolute error = 2.89\n",
      "Root mean squared error = 4.1\n"
     ]
    }
   ],
   "source": [
    "score_model(linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': 0.03515625,\n",
      " 'Age': 0.5784039742947015,\n",
      " 'DRB%': 1.375,\n",
      " 'DRtg': 111636329189394.53,\n",
      " 'FT/FGA': 7.740234375,\n",
      " 'FTr': -4.87890625,\n",
      " 'NRtg': 153389771611121.06,\n",
      " 'OFT/FGA': -1.06640625,\n",
      " 'ORB%': 3.277099609375,\n",
      " 'ORtg': -120766236182078.25,\n",
      " 'OTOV%': 1.58251953125,\n",
      " 'OeFG%': -2.9140625,\n",
      " 'Pace': 0.1015625,\n",
      " 'TOV%': -2.62890625,\n",
      " 'TS%': -6.7109375,\n",
      " 'eFG%': 11.91015625}\n",
      "Intercept:  40.37324783595032\n"
     ]
    }
   ],
   "source": [
    "unpack_model('lr', linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model is quite accurate, some of the coeficients have really high values, which is a symptom of over fitting. The liner regression model is trying to match the results too acurately, that the algorithm is too data specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as linear_regression.pickle\n"
     ]
    }
   ],
   "source": [
    "save_model(linear_regression, 'linear_regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model\n",
    "Since the Linear model has some extremely high coeficient values, we can now use the Ridge model to remedy the overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained and created\n"
     ]
    }
   ],
   "source": [
    "ridge = create_model('ridge', linear_model.Ridge(alpha=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score = 0.88\n",
      "Mean absolute error = 2.86\n",
      "Root mean squared error = 4.09\n"
     ]
    }
   ],
   "source": [
    "score_model(ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': 0.03395036618622866,\n",
      " 'Age': 0.6454712077285601,\n",
      " 'DRB%': 1.2722675625967148,\n",
      " 'DRtg': -2.7664799187290705,\n",
      " 'FT/FGA': 3.5393412795508805,\n",
      " 'FTr': -2.3006404346553393,\n",
      " 'NRtg': 3.0064392117037184,\n",
      " 'OFT/FGA': -1.0549815630012453,\n",
      " 'ORB%': 3.18429774513603,\n",
      " 'ORtg': 1.2612578313085998,\n",
      " 'OTOV%': 1.5185209291590844,\n",
      " 'OeFG%': -2.8592562437605826,\n",
      " 'Pace': 0.10067155671978029,\n",
      " 'TOV%': -2.631099942109758,\n",
      " 'TS%': -0.07836925994716615,\n",
      " 'eFG%': 5.538944136064887}\n",
      "Intercept:  40.38244514106582\n"
     ]
    }
   ],
   "source": [
    "unpack_model('ridge', ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients are all much more reasonable in magnitude as compared to the prior regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as ridge.pickle\n"
     ]
    }
   ],
   "source": [
    "save_model(ridge, 'ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lasso Model\n",
    "Since this data has many columns, we might want the ability to wittle down the effective columns and for this we employ the lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained and created\n"
     ]
    }
   ],
   "source": [
    "lasso = create_model('lasso', linear_model.Lasso(alpha=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score = 0.88\n",
      "Mean absolute error = 2.78\n",
      "Root mean squared error = 4.0\n"
     ]
    }
   ],
   "source": [
    "score_model(lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': -0.0,\n",
      " 'Age': 0.5858091338812544,\n",
      " 'DRB%': -0.0,\n",
      " 'DRtg': -0.0,\n",
      " 'FT/FGA': 0.0,\n",
      " 'FTr': -0.0,\n",
      " 'NRtg': 10.928436734435957,\n",
      " 'OFT/FGA': -0.1561243486930151,\n",
      " 'ORB%': 0.20139819315098914,\n",
      " 'ORtg': 0.7051996696978766,\n",
      " 'OTOV%': -0.0,\n",
      " 'OeFG%': -0.3028669717298625,\n",
      " 'Pace': 0.23056080992662434,\n",
      " 'TOV%': -0.0,\n",
      " 'TS%': 0.44977195213090093,\n",
      " 'eFG%': 0.0}\n",
      "Intercept:  40.38244514106583\n"
     ]
    }
   ],
   "source": [
    "unpack_model('lasso', lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has allowed us to zero in some of the more influential factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as lasso.pickle\n"
     ]
    }
   ],
   "source": [
    "save_model(lasso, 'lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Concepts: the Elastic Model\n",
    "These models all have their own strengths and weaknesses, so there is also the elastic model that combines the idea of restricting coefficient values, as well as setting as many to zero as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained and created\n"
     ]
    }
   ],
   "source": [
    "elastic = create_model('elastic', linear_model.ElasticNet(alpha=0.1, l1_ratio=0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Elastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score = 0.88\n",
      "Mean absolute error = 2.84\n",
      "Root mean squared error = 4.06\n"
     ]
    }
   ],
   "source": [
    "score_model(elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Elastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': -0.006049679275853836,\n",
      " 'Age': 0.6473811537341092,\n",
      " 'DRB%': 0.0,\n",
      " 'DRtg': -2.839709399076666,\n",
      " 'FT/FGA': 0.0,\n",
      " 'FTr': 0.0,\n",
      " 'NRtg': 5.6689142204162595,\n",
      " 'OFT/FGA': -0.386286496670391,\n",
      " 'ORB%': 0.9266819722569105,\n",
      " 'ORtg': 3.023415964424079,\n",
      " 'OTOV%': 0.2582669874404685,\n",
      " 'OeFG%': -1.0954479868155897,\n",
      " 'Pace': 0.12276564256219205,\n",
      " 'TOV%': -0.7282996765340775,\n",
      " 'TS%': 1.4655998965826516,\n",
      " 'eFG%': 0.6948438260103151}\n",
      "Intercept:  40.38244514106583\n"
     ]
    }
   ],
   "source": [
    "unpack_model('elastic', elastic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now reached a middle ground between the sparsity of factors and the interpretable coefficients with this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Elastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as elastic.pickle\n"
     ]
    }
   ],
   "source": [
    "save_model(elastic, 'elastic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Different Type of Linear Regression\n",
    "#### Bayesian Regression\n",
    "With this method, we can obtain the number of wins in a distrobution, instead of simply obtain one exact number. We can also use the same charecteristic of the Ridge model to lessen the effect of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained and created\n"
     ]
    }
   ],
   "source": [
    "bayesian_ridge = create_model('bayesian_ridge', linear_model.BayesianRidge())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Ridge Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score = 0.88\n",
      "Mean absolute error = 2.84\n",
      "Root mean squared error = 4.07\n"
     ]
    }
   ],
   "source": [
    "score_model(bayesian_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Ridge Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': 0.003243891942481092,\n",
      " 'Age': 0.6572435211752546,\n",
      " 'DRB%': 1.1084192450472063,\n",
      " 'DRtg': -2.6658995421050977,\n",
      " 'FT/FGA': 1.4721156144740246,\n",
      " 'FTr': -0.9962156616901832,\n",
      " 'NRtg': 3.5285018124646674,\n",
      " 'OFT/FGA': -0.9739393486058664,\n",
      " 'ORB%': 2.5670667037275723,\n",
      " 'ORtg': 2.017325835243188,\n",
      " 'OTOV%': 1.3574213328541813,\n",
      " 'OeFG%': -2.6469497417430725,\n",
      " 'Pace': 0.15188636416808216,\n",
      " 'TOV%': -2.0800772880048677,\n",
      " 'TS%': 2.0764235894360716,\n",
      " 'eFG%': 2.478449807807311}\n",
      "Intercept:  40.38244514106582\n",
      "Alpha:  0.05666902020111394\n",
      "Lambda:  0.21771479100674457\n"
     ]
    }
   ],
   "source": [
    "unpack_model('bayesian_ridge', bayesian_ridge)\n",
    "br = bayesian_ridge.named_steps['bayesian_ridge']\n",
    "print('Alpha: ', br.alpha_)\n",
    "print('Lambda: ', br.lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are representative of the normal distrobution that the model gives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Ridge Bayesian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as bayesian_ridge.pickle\n"
     ]
    }
   ],
   "source": [
    "save_model(bayesian_ridge, 'bayesian_ridge')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f297435e7483730f90c95e4704d8a04a13ec840de4923b2310ae22b6393e10ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nba-data-analysis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
