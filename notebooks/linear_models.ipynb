{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import pprint\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Spliting of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(957, 16) (957,) (169, 16) (169,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/teams_normalized.csv')\n",
    "\n",
    "# separating the dataset into section ready for model fitting\n",
    "train, test = train_test_split(data, test_size=0.15, train_size=0.85)\n",
    "x_cols = ['Age', 'ORtg', 'DRtg', 'NRtg', 'Pace', '3PAr_Norm', 'FTr', 'TS%', 'eFG%', 'TOV%', 'ORB%', 'FT/FGA', 'OeFG%', 'OTOV%', 'DRB%', 'OFT/FGA']\n",
    "y_col = 'W'\n",
    "\n",
    "x_train = train[x_cols]\n",
    "y_train = train[y_col]\n",
    "x_test= test[x_cols]\n",
    "y_test = test[y_col]\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "We can now run the linear regression algorithm on the split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression = Pipeline(\n",
    "  steps=[('scaler', StandardScaler()), ('lr', linear_model.LinearRegression())])\n",
    "\n",
    "# fitting the model\n",
    "linear_regression.fit(x_train, y_train)\n",
    "\n",
    "# testing the model\n",
    "y_pred = linear_regression.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the test set:  0.86 \n",
      "\n",
      "R2 score = 0.86\n",
      "Mean absolute error = 3.12\n",
      "Root mean squared error = 4.61\n"
     ]
    }
   ],
   "source": [
    "accuracy = linear_regression.score(x_test, y_test)\n",
    "print(\"Model accuracy on the test set: \", round(accuracy, 2), '\\n')\n",
    "\n",
    "# Baseline Model accuracy\n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, y_pred), 2))\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, y_pred), 2)) \n",
    "print(\"Root mean squared error =\", round(math.sqrt(metrics.mean_squared_error(y_test, y_pred)), 2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': 0.08984375,\n",
      " 'Age': 0.6759997646140283,\n",
      " 'DRB%': 0.81787109375,\n",
      " 'DRtg': 104541620820097.9,\n",
      " 'FT/FGA': 2.49609375,\n",
      " 'FTr': -1.615234375,\n",
      " 'NRtg': 144318916827112.12,\n",
      " 'OFT/FGA': -0.8125,\n",
      " 'ORB%': 2.9736328125,\n",
      " 'ORtg': -114096159853452.33,\n",
      " 'OTOV%': 0.78179931640625,\n",
      " 'OeFG%': -1.8671875,\n",
      " 'Pace': 0.1328125,\n",
      " 'TOV%': -2.396484375,\n",
      " 'TS%': 0.984375,\n",
      " 'eFG%': 3.90625}\n",
      "Intercept:  40.08539138227167\n"
     ]
    }
   ],
   "source": [
    "lr = linear_regression.named_steps['lr']\n",
    "\n",
    "pprint.pprint(dict(zip(x_cols, lr.coef_)))\n",
    "print(\"Intercept: \", lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model is quite accurate, some of the coeficients have really high values, which is a symptom of over fitting. The liner regression model is trying to match the results too acurately, that the algorithm is too data specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/linear_models/linear_regression.pickle\", \"wb\") as f:\n",
    "  pickle.dump(linear_regression, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Model\n",
    "Since the Linear model has some extremely high coeficient values, we can now use the Ridge model to remedy the overfitting.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Pipeline(steps=[('scaler', StandardScaler()), ('ridge', linear_model.Ridge(alpha=.5))])\n",
    "\n",
    "# fitting the model\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# testing the model\n",
    "ridge_y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Ridge Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the test set:  0.86 \n",
      "\n",
      "R2 score = 0.86\n",
      "Mean absolute error = 3.12\n",
      "Root mean squared error = 4.63\n"
     ]
    }
   ],
   "source": [
    "ridge_accuracy = ridge.score(x_test, y_test)\n",
    "print(\"Model accuracy on the test set: \", round(ridge_accuracy, 2), '\\n')\n",
    "\n",
    "# Baseline Model accuracy\n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, ridge_y_pred), 2))\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, ridge_y_pred), 2)) \n",
    "print(\"Root mean squared error =\", round(math.sqrt(metrics.mean_squared_error(y_test, ridge_y_pred)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': 0.04620336840960141,\n",
      " 'Age': 0.6704251276514837,\n",
      " 'DRB%': 0.7769499864427234,\n",
      " 'DRtg': -3.2865385701532235,\n",
      " 'FT/FGA': 1.6596162943501909,\n",
      " 'FTr': -1.1019356330343018,\n",
      " 'NRtg': 3.755058821846545,\n",
      " 'OFT/FGA': -0.8080738316434724,\n",
      " 'ORB%': 2.6807904609590576,\n",
      " 'ORtg': 1.7384104165708651,\n",
      " 'OTOV%': 0.7856099216709219,\n",
      " 'OeFG%': -1.9367330201422028,\n",
      " 'Pace': 0.19910230365454884,\n",
      " 'TOV%': -2.1589405704662674,\n",
      " 'TS%': 1.86982071259111,\n",
      " 'eFG%': 2.6245124195049074}\n",
      "Intercept:  40.083594566353185\n"
     ]
    }
   ],
   "source": [
    "ridge_model = ridge.named_steps['ridge']\n",
    "\n",
    "pprint.pprint(dict(zip(x_cols, ridge_model.coef_)))\n",
    "print(\"Intercept: \", ridge_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These coefficients are all much more reasonable in magnitude as compared to the prior regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Ridge Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/linear_models/ridge.pickle\", \"wb\") as f:\n",
    "  pickle.dump(ridge, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Lasso Model\n",
    "Since this data has many columns, we might want the ability to wittle down the effective columns and for this we employ the lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Pipeline(\n",
    "  steps=[('scaler', StandardScaler()), \n",
    "  ('lasso', linear_model.Lasso(alpha=0.1))])\n",
    "\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "lasso_y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on the test set:  0.86 \n",
      "\n",
      "R2 score = 0.86\n",
      "Mean absolute error = 3.07\n",
      "Root mean squared error = 4.62\n"
     ]
    }
   ],
   "source": [
    "lasso_accuracy = lasso.score(x_test, y_test)\n",
    "print(\"Model accuracy on the test set: \", round(lasso_accuracy, 2), '\\n')\n",
    "\n",
    "# Baseline Model accuracy\n",
    "print(\"R2 score =\", round(metrics.r2_score(y_test, lasso_y_pred), 2))\n",
    "print(\"Mean absolute error =\", round(metrics.mean_absolute_error(y_test, lasso_y_pred), 2)) \n",
    "print(\"Root mean squared error =\", round(math.sqrt(metrics.mean_squared_error(y_test, lasso_y_pred)), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unpacking the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3PAr_Norm': -0.0,\n",
      " 'Age': 0.6325781045002427,\n",
      " 'DRB%': -0.0,\n",
      " 'DRtg': -0.0,\n",
      " 'FT/FGA': 0.0,\n",
      " 'FTr': -0.0,\n",
      " 'NRtg': 10.693290631725096,\n",
      " 'OFT/FGA': -0.26367283620476933,\n",
      " 'ORB%': 0.20629287709595318,\n",
      " 'ORtg': 0.8810534117913228,\n",
      " 'OTOV%': -0.0,\n",
      " 'OeFG%': -0.4394722485194868,\n",
      " 'Pace': 0.2812723894180477,\n",
      " 'TOV%': -0.0,\n",
      " 'TS%': 0.33599544638378054,\n",
      " 'eFG%': 0.0}\n",
      "Intercept:  40.083594566353185\n"
     ]
    }
   ],
   "source": [
    "lasso_model = lasso.named_steps['lasso']\n",
    "\n",
    "pprint.pprint(dict(zip(x_cols, lasso_model.coef_)))\n",
    "print(\"Intercept: \", lasso_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has allowed us to zero in some of the more influential factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/linear_models/lasso.pickle\", \"wb\") as f:\n",
    "  pickle.dump(ridge, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f297435e7483730f90c95e4704d8a04a13ec840de4923b2310ae22b6393e10ed"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nba-data-analysis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
